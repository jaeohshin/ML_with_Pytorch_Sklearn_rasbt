{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjMvgExvv5hYbWXohU82wx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaeohshin/ML_with_Pytorch_Sklearn_rasbt/blob/main/ch15_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3MMZ_78WyHT6"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "5o7e7mgmyNpL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5fMoonfytdb",
        "outputId": "0cce662f-f2c6-4eb6-fdb1-35bef24adf42"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.0->torchtext)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchtext) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.3.0->torchtext) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install portalocker"
      ],
      "metadata": {
        "id": "JpEytmZ-zPrs",
        "outputId": "49625751-bc3f-4f9e-893c-55ee451e33f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import IMDB\n",
        "from torch.utils.data.dataset import random_split"
      ],
      "metadata": {
        "id": "PMhSNVW5ySQl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e0e2061-dcf4-4321-b1fe-1058a57e5cf5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/datasets/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/data/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchdata"
      ],
      "metadata": {
        "id": "YtCfgMOXzewm",
        "outputId": "e260f77a-2c9a-44ea-dd07-08805a470d43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchdata\n",
            "  Downloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.31.0)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata) (12.5.82)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata) (1.3.0)\n",
            "Downloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchdata\n",
            "Successfully installed torchdata-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: load and create the datasets\n",
        "\n",
        "train_dataset = IMDB(split='train')\n",
        "test_dataset = IMDB(split='test')\n",
        "\n",
        "test_dataset = list(test_dataset)\n",
        "\n",
        "torch.manual_seed(1)\n",
        "train_dataset, valid_dataset = random_split(\n",
        "    list(train_dataset), [20000, 5000])"
      ],
      "metadata": {
        "id": "-13HaFxhyZE_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "828C796lz8ub"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "metadata": {
        "id": "UfcsqXjIzpGz",
        "outputId": "2b722bed-fd7b-4927-a5d0-2975c7294f77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20000\n",
            "25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 2: find unique tokens (words)\n",
        "import re\n",
        "from collections import Counter, OrderedDict\n",
        "\n",
        "token_counts = Counter()\n",
        "\n",
        "def tokenizer(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
        "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
        "        ' '.join(emoticons).replace('-', '')\n",
        "    tokenized = text.split()\n",
        "    return tokenized\n",
        "\n",
        "for label, line in train_dataset:\n",
        "    tokens = tokenizer(line)\n",
        "    token_counts.update(tokens)\n",
        "\n",
        "print('Vocab-size:', len(token_counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8orUbK_yoOA",
        "outputId": "b7a03089-74d8-40a8-f221-c18c77463dc3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab-size: 69023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 3: encoding each unique token into integers\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "\n",
        "vocab = vocab(ordered_dict)\n",
        "\n",
        "vocab.insert_token(\"<pad>\", 0)\n",
        "vocab.insert_token(\"<unk>\", 1)\n",
        "vocab.set_default_index(1)\n",
        "\n",
        "print([vocab[token] for token in ['this', 'is', 'an', 'example']])\n",
        "print([vocab[token] for token in ['I', 'am', 'a', 'boy']])"
      ],
      "metadata": {
        "id": "Z31ASA0R0LL2",
        "outputId": "0dd39e95-cc64-4e13-f378-dcd71d887c82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11, 7, 35, 457]\n",
            "[1, 244, 4, 408]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not torch.cuda.is_available():\n",
        "    print(\"Warning: this code may be very slow on CPU\")"
      ],
      "metadata": {
        "id": "ssFMixUe2Jku",
        "outputId": "d6b2ea66-4406-4772-e3d3-c826f9fa7c95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: this code may be very slow on CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext"
      ],
      "metadata": {
        "id": "HwoSkQks5-22"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 3-A: define the functions for transformation\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
        "\n",
        "from torchtext import __version__ as torchtext_version\n",
        "from pkg_resources import parse_version\n",
        "\n",
        "if parse_version(torchtext.__version__) > parse_version(\"0.10\"):\n",
        "    label_pipeline = lambda x: 1. if x == 2 else 0.         # 1 ~ 부정 리뷰, 2 ~ 긍정 리뷰\n",
        "else:\n",
        "    label_pipeline = lambda x: 1. if x == 'pos' else 0.\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, lengths = [], [], []\n",
        "    for _label, _text in batch:\n",
        "        label_list.append(label_pipeline(_label)) ## Either 1 or 0\n",
        "        processed_text = torch.tensor(text_pipeline(_text),  ##text --> torken\n",
        "                                      dtype=torch.int64)\n",
        "        text_list.append(processed_text)\n",
        "        lengths.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list)\n",
        "    lengths = torch.tensor(lengths)\n",
        "    padded_text_list = nn.utils.rnn.pad_sequence(\n",
        "        text_list, batch_first=True)\n",
        "    return padded_text_list.to(device), label_list.to(device), lengths.to(device)\n"
      ],
      "metadata": {
        "id": "nqHAvDxT3GhQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Take a small batch\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False, collate_fn=collate_batch)\n",
        "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
        "print(text_batch)\n",
        "print(label_batch)\n",
        "print(length_batch)\n",
        "print(text_batch.shape)"
      ],
      "metadata": {
        "id": "aGLaJTEq5uzi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d49156d3-1885-4594-9a74-e8f277eabc25"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   35,  1739,     7,   449,   721,     6,   301,     4,   787,     9,\n",
            "             4,    18,    44,     2,  1705,  2460,   186,    25,     7,    24,\n",
            "           100,  1874,  1739,    25,     7, 34415,  3568,  1103,  7517,   787,\n",
            "             5,     2,  4991, 12401,    36,     7,   148,   111,   939,     6,\n",
            "         11598,     2,   172,   135,    62,    25,  3199,  1602,     3,   928,\n",
            "          1500,     9,     6,  4601,     2,   155,    36,    14,   274,     4,\n",
            "         42945,     9,  4991,     3,    14, 10296,    34,  3568,     8,    51,\n",
            "           148,    30,     2,    58,    16,    11,  1893,   125,     6,   420,\n",
            "          1214,    27, 14542,   940,    11,     7,    29,   951,    18,    17,\n",
            "         15994,   459,    34,  2480, 15211,  3713,     2,   840,  3200,     9,\n",
            "          3568,    13,   107,     9,   175,    94,    25,    51, 10297,  1796,\n",
            "            27,   712,    16,     2,   220,    17,     4,    54,   722,   238,\n",
            "           395,     2,   787,    32,    27,  5236,     3,    32,    27,  7252,\n",
            "          5118,  2461,  6390,     4,  2873,  1495,    15,     2,  1054,  2874,\n",
            "           155,     3,  7015,     7,   409,     9,    41,   220,    17,    41,\n",
            "           390,     3,  3925,   807,    37,    74,  2858,    15, 10297,   115,\n",
            "            31,   189,  3506,   667,   163,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  216,   175,   724,     5,    11,    18,    10,   226,   110,    14,\n",
            "           182,    78,     8,    13,    24,   182,    78,     8,    13,   166,\n",
            "           182,    50,   150,    24,    85,     2,  4031,  5935,   107,    96,\n",
            "            28,  1867,   602,    19,    52,   162,    21,  1698,     8,     6,\n",
            "          1181,   367,     2,   351,    10,   140,   419,     4,   333,     5,\n",
            "          6022,  7136,  5055,  1209, 10892,    32,   219,     9,     2,   405,\n",
            "          1413,    13,  4031,    13,  1099,     7,    85,    19,     2,    20,\n",
            "          1018,     4,    85,   565,    34,    24,   807,    55,     5,    68,\n",
            "           658,    10,   507,     8,     4,   668,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [   10,   121,    24,    28,    98,    74,   589,     9,   149,     2,\n",
            "          7372,  3030, 14543,  1012,   520,     2,   985,  2327,     5, 16847,\n",
            "          5479,    19,    25,    67,    76,  3478,    38,     2,  7372,     3,\n",
            "            25,    67,    76,  2951,    34,    35, 10893,   155,   449, 29495,\n",
            "         23725,    10,    67,     2,   554,    12, 14543,    67,    91,     4,\n",
            "            50,    20,    19,     8,    67,    24,  4228,     2,  2142,    37,\n",
            "            33,  3478,    87,     3,  2564,   160,   155,    11,   634,   126,\n",
            "            24,   158,    72,   286,    13,   373,     2,  4804,    19,     2,\n",
            "          7372,  6794,     6,    30,   128,    73,    48,    10,   886,     8,\n",
            "            13,    24,     4,    85,    20,    19,     8,    13,    35,   218,\n",
            "             3,   428,   710,     2,   107,   936,     7,    54,    72,   223,\n",
            "             3,    10,    96,   122,     2,   103,    54,    72,    82,     2,\n",
            "           658,   202,     2,   106,   293,   103,     7,  1193,     3,  3031,\n",
            "           708,  5760,     3,  2918,  3991,   706,  3327,   349,   148,   286,\n",
            "            13,   139,     6,     2,  1501,   750,    29,  1407,    62,    65,\n",
            "          2612,    71,    40,    14,     4,   547,     9,    62,     8,  7943,\n",
            "            71,    14,     2,  5687,     5,  4868,  3111,     6,   205,     2,\n",
            "            18,    55,  2075,     3,   403,    12,  3111,   231,    45,     5,\n",
            "           271,     3,    68,  1400,     7,  9774,   932,    10,   102,     2,\n",
            "            20,   143,    28,    76,    55,  3810,     9,  2723,     5,    12,\n",
            "            10,   379,     2,  7372,    15,     4,    50,   710,     8,    13,\n",
            "            24,   887,    32,    31,    19,     8,    13,   428],\n",
            "        [18923,     7,     4,  4753,  1669,    12,  3019,     6,     4, 13906,\n",
            "           502,    40,    25,    77,  1588,     9,   115,     6, 21713,     2,\n",
            "            90,   305,   237,     9,   502,    33,    77,   376,     4, 16848,\n",
            "           847,    62,    77,   131,     9,     2,  1580,   338,     5, 18923,\n",
            "            32,     2,  1980,    49,   157,   306, 21713,    46,   981,     6,\n",
            "         10298,     2, 18924,   125,     9,   502,     3,   453,     4,  1852,\n",
            "           630,   407,  3407,    34,   277,    29,   242,     2, 20200,     5,\n",
            "         18923,    77,    95,    41,  1833,     6,  2105,    56,     3,   495,\n",
            "           214,   528,     2,  3479,     2,   112,     7,   181,  1813,     3,\n",
            "           597,     5,     2,   156,   294,     4,   543,   173,     9,  1562,\n",
            "           289, 10038,     5,     2,    20,    26,   841,  1392,    62,   130,\n",
            "           111,    72,   832,    26,   181, 12402,    15,    69,   183,     6,\n",
            "            66,    55,   936,     5,     2,    63,     8,     7,    43,     4,\n",
            "            78, 23726, 15995,    13,    20,    17,   800,     5,   392,    59,\n",
            "          3992,     3,   371,   103,  2596,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0]])\n",
            "tensor([1., 1., 1., 0.])\n",
            "tensor([165,  86, 218, 145])\n",
            "torch.Size([4, 218])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 4: batching the datasets\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dl = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                      shuffle=True, collate_fn=collate_batch)\n",
        "valid_dl = DataLoader(valid_dataset, batch_size=batch_size,\n",
        "                      shuffle=False, collate_fn=collate_batch)\n",
        "test_dl = DataLoader(test_dataset, batch_size=batch_size,\n",
        "                      shuffle=False, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "MCpLP42SSOqU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## I don't understand this\n",
        "embedding = nn.Embedding(\n",
        "    num_embeddings=10,\n",
        "    embedding_dim=3,\n",
        "    padding_idx=0\n",
        ")"
      ],
      "metadata": {
        "id": "FnYDTay6UZZP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD0GT9tM_Imq",
        "outputId": "ca597902-0edb-4729-8398-4308fc9e7496"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(10, 3, padding_idx=0)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_encoded_input = torch.LongTensor([1, 2, 4, 5])\n",
        "print(embedding(text_encoded_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnbhXCHh_KCT",
        "outputId": "4fc9ca2b-5f3c-4679-d1cd-8ca16a263ae3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.7039, -0.8321, -0.4651],\n",
            "        [-0.3203,  2.2408,  0.5566],\n",
            "        [-0.4643,  0.3046,  0.7046],\n",
            "        [-0.7106, -0.2959,  0.8356]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## RNN model\n",
        "\n",
        "## Fully connected NN with one hidden layer\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(input_size,\n",
        "                          hidden_size,\n",
        "                          num_layers=2,\n",
        "                          batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, hidden = self.rnn(x)\n",
        "        out = hidden[-1, :, :]\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "model = RNN(64, 32)\n",
        "print(model)\n",
        "\n",
        "print(torch.randn(5, 3, 64))\n",
        "model(torch.randn(5, 3, 64))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeQ2P60A_R0r",
        "outputId": "73dd3522-7cff-48ca-e372-9e02d57eefa1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(\n",
            "  (rnn): RNN(64, 32, num_layers=2, batch_first=True)\n",
            "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n",
            "tensor([[[-1.0810e+00,  6.6615e-01,  1.9219e+00,  9.6117e-02, -7.9712e-02,\n",
            "           7.7696e-01, -1.7452e+00, -2.1778e-03,  1.0749e+00, -1.3411e+00,\n",
            "          -1.4795e-01, -4.6597e-01,  2.4034e+00,  9.3753e-01, -1.2597e+00,\n",
            "           5.9246e-01,  9.0927e-01, -1.0327e+00, -4.6185e-01, -1.0440e+00,\n",
            "           5.1613e-01,  6.8916e-01,  1.0687e+00, -1.3540e+00,  4.6383e-01,\n",
            "          -1.2614e+00,  8.4420e-01, -9.3638e-01,  3.6146e-01, -8.4201e-01,\n",
            "          -1.4112e+00,  2.2160e-01, -3.3505e-01,  9.3662e-01,  1.0012e+00,\n",
            "           2.0224e-01,  5.3106e-01, -3.4890e-01,  9.0318e-01, -9.0782e-01,\n",
            "           1.1209e+00, -9.1154e-01,  1.2498e+00, -8.6132e-01,  6.9887e-01,\n",
            "          -1.3652e+00,  8.0527e-01, -1.4619e-01, -2.7935e-01,  9.0784e-01,\n",
            "          -1.5942e+00,  6.8963e-02,  1.0600e+00,  1.0474e+00,  3.7864e-01,\n",
            "          -1.2508e+00, -3.2177e-01, -6.1151e-01,  9.4741e-01, -1.8107e+00,\n",
            "          -9.0311e-02,  1.6804e+00,  3.1972e-01, -5.9539e-01],\n",
            "         [ 1.1408e-01, -2.6918e-01, -1.3225e+00,  1.1891e+00,  1.1782e-02,\n",
            "          -2.1285e+00, -1.5214e+00,  2.0923e+00, -6.7383e-01, -5.4135e-02,\n",
            "          -9.5486e-01,  8.5073e-01,  6.3062e-01, -7.1752e-01, -1.1708e+00,\n",
            "          -6.3712e-02, -1.7052e-01,  1.3265e+00,  9.4637e-01,  2.8098e+00,\n",
            "          -1.3685e+00, -6.7317e-01,  5.8275e-01, -7.7269e-01, -1.5089e+00,\n",
            "          -6.1997e-01,  7.0544e-01,  6.6514e-01,  4.4243e-01, -7.3918e-01,\n",
            "           3.1225e-01,  1.3245e-01, -5.2582e-02,  6.6710e-01,  2.4293e-01,\n",
            "           3.9854e-01,  2.8323e-02, -3.6688e-01,  1.1310e+00, -1.2307e+00,\n",
            "           2.1645e+00, -1.1648e-01, -7.2117e-01, -1.4563e+00,  3.4184e-01,\n",
            "          -8.5435e-01, -6.0252e-01, -1.2267e+00, -1.0471e+00, -2.7692e-01,\n",
            "           1.0536e+00, -8.6917e-01, -7.4756e-02,  7.3762e-01,  1.1940e+00,\n",
            "          -3.2136e-01, -1.4911e+00,  2.2060e-01,  3.8781e-01, -2.1536e+00,\n",
            "           1.9064e-02,  8.5201e-01, -2.9812e-01,  1.2109e-01],\n",
            "         [ 1.9189e-01,  6.8871e-01,  1.9079e-01, -3.7180e-01,  4.4909e-02,\n",
            "           8.6498e-01,  7.5475e-01, -7.7052e-01,  1.2802e+00, -2.7712e-01,\n",
            "          -2.3565e-01,  7.5509e-01, -1.1653e+00, -2.4556e-01,  1.1506e+00,\n",
            "          -4.1684e-01, -1.4964e+00, -5.5462e-01, -1.0910e+00, -4.8117e-01,\n",
            "           1.5248e+00,  3.9563e-01,  4.7078e-01, -4.0703e-01, -5.3021e-01,\n",
            "           3.5660e-01,  1.0004e+00, -1.3690e-02,  3.1003e-01,  2.5014e-02,\n",
            "           7.8228e-01, -5.1470e-02, -1.3690e+00, -5.2387e-01,  7.3105e-02,\n",
            "          -4.0377e-01,  2.2408e-01,  2.5242e+00,  1.1041e+00,  1.6937e+00,\n",
            "          -6.9431e-01, -1.6550e-01, -2.7233e+00,  4.4057e-01, -1.2427e+00,\n",
            "          -8.9733e-01, -1.3145e+00,  1.1379e+00, -1.2283e-01,  1.2087e+00,\n",
            "          -2.2120e-02, -7.0392e-01, -1.2628e+00, -6.3291e-01,  6.4020e-01,\n",
            "          -2.0637e-01, -6.5623e-02, -7.5515e-01,  1.2367e+00,  1.7252e+00,\n",
            "           1.1378e+00, -4.5504e-01, -1.5538e+00, -2.6453e+00]],\n",
            "\n",
            "        [[-1.3163e+00,  4.0663e-01,  4.0035e-01,  4.5641e-01, -7.2388e-01,\n",
            "          -4.1841e-01,  1.0471e+00, -1.3861e+00,  5.1352e-01,  5.7016e-02,\n",
            "           1.4200e+00, -4.3381e-01,  1.5062e-01,  8.6641e-01, -9.5492e-01,\n",
            "          -2.1121e+00,  7.6391e-01, -9.9495e-01, -2.8676e-01, -3.1504e-01,\n",
            "           3.0283e-01, -4.7492e-01,  8.7200e-01, -8.0651e-02,  2.1659e-02,\n",
            "           1.2560e+00, -1.2095e+00,  9.3579e-02,  1.3379e+00, -9.2589e-02,\n",
            "          -1.3838e+00, -1.6598e+00,  1.7606e+00,  1.8116e+00, -1.5855e+00,\n",
            "           9.6927e-01,  9.2179e-01,  2.9220e-01, -1.1575e+00, -7.0348e-01,\n",
            "          -1.7056e+00,  9.1421e-02, -5.9711e-01,  5.1932e-01,  1.5194e+00,\n",
            "          -1.5022e+00, -2.6280e-01, -5.2351e-01, -2.5269e-01,  1.4633e+00,\n",
            "           2.5283e-01,  1.8608e+00, -1.4854e+00,  6.0394e-01,  7.8966e-01,\n",
            "           1.0433e-01, -1.3990e+00, -4.5668e-02,  1.3887e+00,  5.6094e-01,\n",
            "          -9.5559e-01, -9.2258e-01, -1.9008e-01, -4.3052e-01],\n",
            "         [ 9.3182e-01, -2.1636e+00, -1.6162e-01, -2.1223e+00, -2.3478e-01,\n",
            "          -1.6105e-01,  1.1252e-01, -9.5525e-01,  1.2109e+00, -7.4490e-01,\n",
            "           1.7655e-01,  5.4333e-01, -6.1486e-02,  1.6070e+00,  7.7727e-01,\n",
            "           3.8629e-01,  7.5172e-01,  1.3600e+00, -2.5150e-02,  5.7644e-01,\n",
            "          -5.9973e-01, -6.0178e-01, -3.5553e-01,  8.9080e-01, -8.4062e-01,\n",
            "           2.0029e+00, -2.7761e-01, -3.0429e-01, -6.2420e-01, -1.4315e+00,\n",
            "           2.4301e-01, -2.1739e+00, -1.0616e+00,  6.5805e-01, -6.3968e-01,\n",
            "           5.8034e-01, -9.2888e-01,  1.6048e+00,  7.1030e-01, -1.5657e+00,\n",
            "           1.5740e+00, -2.7023e-01, -2.5961e-01,  6.7666e-01,  3.2502e-01,\n",
            "           1.7831e+00,  2.0796e+00, -1.2396e+00,  1.6179e+00,  4.0626e-01,\n",
            "          -6.6545e-01,  5.4388e-01, -2.0811e-01, -2.3215e-01,  1.8973e+00,\n",
            "           2.2744e-01,  5.0364e-02,  1.3372e+00,  6.6401e-01, -3.8539e-01,\n",
            "           1.0283e+00,  8.0217e-01, -3.6694e-01,  4.6315e-01],\n",
            "         [-1.1090e+00,  1.3573e-01, -9.7259e-01,  1.3574e-01, -1.8035e+00,\n",
            "          -1.2634e+00, -7.3641e-01,  6.2620e-01,  8.1411e-01,  1.6146e+00,\n",
            "           4.9640e-01, -1.0884e+00, -2.3930e-01,  7.7865e-01, -1.7313e+00,\n",
            "          -1.0313e+00,  6.4614e-02,  4.6102e-01, -1.1041e+00, -9.2807e-01,\n",
            "           4.8366e-01,  6.5789e-02,  2.1805e+00, -1.0457e+00, -6.6218e-01,\n",
            "          -4.3098e-01, -6.0348e-01,  2.5829e-01,  5.2414e-01, -3.8267e-01,\n",
            "           3.2279e-01,  7.4239e-01, -2.4717e-01,  1.3853e+00, -4.4557e-01,\n",
            "          -1.1388e+00, -1.1136e+00,  1.0358e+00,  1.5826e+00, -3.3914e-01,\n",
            "           1.0964e-01, -1.2753e+00, -2.7968e-01,  1.7148e+00,  1.5347e-01,\n",
            "          -1.4311e+00, -1.1920e+00,  2.5351e-01, -2.7609e-01, -4.3679e-01,\n",
            "          -1.4630e-01,  6.6416e-01, -2.6311e-01,  1.0650e+00, -8.6441e-01,\n",
            "          -1.1821e+00, -1.2981e+00,  7.9524e-01,  9.0927e-01, -2.0524e-01,\n",
            "          -1.6982e+00,  1.4390e-02,  1.6076e+00, -9.5999e-01]],\n",
            "\n",
            "        [[-8.8837e-01,  1.0429e+00,  1.1757e-02, -1.3640e+00,  4.7543e-01,\n",
            "           4.9856e-01,  1.8401e-01,  5.2495e-01,  6.3331e-01, -4.3737e-01,\n",
            "          -5.8031e-01, -2.9283e-01, -6.6716e-01, -1.1580e-01,  4.2895e-01,\n",
            "           1.2230e+00,  2.7082e-01, -9.1690e-01,  3.4599e-01,  1.4841e-01,\n",
            "           5.5128e-01,  6.9524e-01, -2.8306e+00,  1.2254e+00,  1.6013e+00,\n",
            "          -7.1559e-01,  5.4822e-01,  3.1785e-01,  9.3920e-02, -1.3907e-01,\n",
            "          -4.2210e-01, -5.9613e-01,  8.4104e-01,  7.2904e-01, -4.2326e-01,\n",
            "           4.5935e-01,  1.3829e-01,  6.1543e-01, -6.5528e-01,  4.3270e-01,\n",
            "          -1.3458e+00,  2.8673e+00, -1.1350e+00,  1.0117e+00, -9.3591e-01,\n",
            "           8.1645e-01,  1.4187e+00, -1.5266e+00,  7.9817e-01, -1.7962e+00,\n",
            "           3.4541e-01,  6.5127e-01,  1.3374e+00,  1.3454e+00, -5.4984e-01,\n",
            "          -1.0203e+00, -9.6427e-01,  7.3706e-01,  5.3672e-01, -9.7617e-02,\n",
            "           9.3435e-01,  1.0986e+00,  1.5679e+00, -1.0350e+00],\n",
            "         [-1.2534e-01, -7.6914e-01, -5.8946e-01,  2.6276e-01, -1.0874e+00,\n",
            "           7.1218e-01,  2.6724e-01,  1.2804e-02,  1.3850e+00,  2.3211e-01,\n",
            "          -3.4996e-01, -8.8579e-01, -9.7750e-02,  2.4278e-01, -1.7672e+00,\n",
            "           1.6145e+00,  1.6404e-02, -3.3047e-01, -1.6341e-02,  7.2168e-01,\n",
            "           8.3021e-01,  6.9917e-01, -9.2613e-01, -1.3475e-01,  2.5031e+00,\n",
            "          -5.2710e-01,  7.1230e-01, -4.8007e-01, -1.3688e+00,  1.3450e+00,\n",
            "           4.1587e-01, -2.1955e+00, -1.2530e-01,  2.1080e-01,  1.3756e-02,\n",
            "          -4.1674e-01,  1.4651e+00,  4.1043e-01, -4.1400e-01, -1.0407e+00,\n",
            "           1.1937e+00,  2.4874e-01, -8.5433e-01,  1.1309e+00, -7.7783e-01,\n",
            "          -1.6786e+00,  9.7043e-01,  1.1353e-01, -9.0047e-01,  9.3813e-01,\n",
            "          -4.8187e-01,  8.7483e-01,  1.2102e-01,  1.1366e+00, -3.6348e-01,\n",
            "           1.0505e+00,  2.3103e-01,  2.7569e-01, -2.7264e+00,  9.6857e-01,\n",
            "          -1.0000e+00, -2.7004e-02,  3.3302e-01,  1.8128e-01],\n",
            "         [-1.6466e-01, -9.4961e-01, -4.3218e-01,  2.0921e+00,  1.2037e+00,\n",
            "          -3.4755e-01, -4.2307e-01,  7.0613e-01,  4.7547e-01, -9.5400e-01,\n",
            "           1.2335e+00, -1.2176e+00, -9.9734e-01, -1.0543e+00, -1.3215e+00,\n",
            "          -3.6198e-01,  1.2146e+00,  6.9759e-01, -9.6768e-01, -1.9501e+00,\n",
            "          -5.5669e-01, -1.2866e+00, -1.4618e+00,  5.7141e-02,  5.7099e-01,\n",
            "          -8.5076e-01, -5.7526e-01, -9.0669e-01,  5.8439e-01,  1.4620e+00,\n",
            "          -1.4021e+00,  7.0699e-01, -8.1891e-02, -4.2064e-01, -1.8581e+00,\n",
            "           8.0899e-01, -6.9880e-01,  2.4969e+00, -1.5497e-01,  4.4296e-01,\n",
            "           2.9365e-02,  1.2542e+00,  2.1946e-01, -1.4253e+00, -7.4857e-01,\n",
            "           7.9335e-01,  2.0217e+00, -6.4070e-01,  4.0378e-01,  9.7060e-01,\n",
            "          -1.1673e+00,  6.6004e-04,  8.2501e-01, -1.2495e+00,  1.0830e+00,\n",
            "           2.1865e-01,  2.6165e+00,  9.9448e-01,  1.1474e-01,  6.9084e-03,\n",
            "          -4.3209e-01,  1.3588e+00,  1.7307e-01,  6.0590e-01]],\n",
            "\n",
            "        [[-3.1931e-01,  8.5116e-01,  3.7858e-01, -8.4998e-01,  1.0972e-01,\n",
            "           1.4921e-01, -3.4156e-01, -3.9811e-01,  6.8053e-01,  5.7385e-01,\n",
            "           1.6271e+00, -9.6354e-01,  6.3908e-01, -5.2952e-03,  3.7838e-01,\n",
            "          -5.3244e-01,  9.1539e-01, -5.2732e-01, -3.6852e-01,  9.5691e-02,\n",
            "          -9.0900e-01,  8.4592e-01,  2.1817e+00, -2.6713e-01,  5.1276e-01,\n",
            "          -1.1925e+00,  9.8248e-02,  6.4917e-01, -6.3657e-01,  7.5881e-01,\n",
            "           1.2942e+00,  4.7497e-01, -2.2784e-01, -2.6833e-01, -1.4578e-01,\n",
            "          -1.8171e+00, -9.5186e-01, -3.9185e-01,  6.4151e-01, -4.0958e-01,\n",
            "          -5.0945e-03, -1.2642e+00,  1.3768e+00, -2.7795e-01,  1.3735e+00,\n",
            "           1.0860e+00, -2.0904e+00,  3.0630e-01,  6.6223e-02,  5.3630e-01,\n",
            "          -7.6021e-01,  2.0595e-01,  7.4187e-02,  1.3468e+00,  6.4949e-01,\n",
            "          -3.1500e-01, -1.0155e+00, -1.3589e+00, -3.4313e-01, -1.2765e+00,\n",
            "           1.1239e+00, -6.9296e-02, -4.9493e-01, -1.5184e+00],\n",
            "         [ 1.0752e-01,  1.5788e-01,  5.2156e-01, -7.4120e-01, -6.8736e-01,\n",
            "          -4.6027e-01, -2.0384e+00, -1.8642e-01,  5.8661e-01, -1.2509e+00,\n",
            "          -8.4602e-01, -1.4952e+00,  6.9907e-01,  1.8720e+00,  8.5009e-01,\n",
            "           1.2625e+00,  2.1142e-01,  6.3604e-01,  3.2659e-01, -1.0694e+00,\n",
            "           1.1111e+00,  1.0817e+00,  1.1223e+00,  2.2501e+00, -8.3728e-01,\n",
            "          -9.8264e-02,  5.1821e-02, -1.7091e+00,  2.6578e-01, -3.3412e-01,\n",
            "           9.8819e-01,  1.2842e+00, -6.8296e-01, -1.2923e-01, -1.1554e+00,\n",
            "           5.9792e-01,  9.8022e-02,  4.3958e-01,  1.6750e+00, -5.0640e-01,\n",
            "           6.1670e-01, -3.3126e-01, -7.7608e-02,  4.3196e-01, -7.5116e-01,\n",
            "          -7.6870e-01,  5.6624e-01,  8.8949e-02,  4.2182e-01,  2.9156e+00,\n",
            "           6.1247e-01, -1.6683e+00, -1.2998e+00,  9.7520e-01, -4.3924e-01,\n",
            "          -1.5102e+00, -1.5666e+00,  9.4010e-01,  4.2748e-01, -7.9384e-01,\n",
            "           3.1947e-01,  8.5222e-01,  7.6724e-02,  1.6645e-01],\n",
            "         [ 1.9072e+00, -2.1961e+00,  4.0541e-01,  5.0044e-01,  3.9831e-01,\n",
            "          -5.9265e-01, -4.4197e-01,  6.7962e-01, -1.8830e+00, -9.4617e-01,\n",
            "           8.9713e-01, -2.3735e+00, -5.0068e-01,  7.0284e-02, -1.1225e+00,\n",
            "           1.4402e+00, -1.2923e-01,  8.9836e-01,  1.6357e-01,  1.4333e+00,\n",
            "           4.9797e-02,  6.9001e-01, -1.5869e-01,  7.9485e-01, -1.8970e+00,\n",
            "           8.6307e-01,  5.0867e-01, -7.0056e-01, -1.5037e-01, -9.5968e-01,\n",
            "           1.4930e-01,  1.1416e+00,  2.5255e-01,  4.3949e-01,  2.2353e+00,\n",
            "          -2.3016e-01,  1.6853e-01,  6.7002e-02,  2.3217e+00, -1.7003e+00,\n",
            "           1.4747e+00, -3.6077e-01, -1.4042e+00,  7.5763e-01,  6.5332e-01,\n",
            "           6.0399e-01, -5.7096e-01, -2.0810e-01,  7.2148e-01, -1.4402e+00,\n",
            "           3.6247e-01, -5.6084e-01,  7.6887e-01,  1.7350e+00,  6.6639e-01,\n",
            "          -6.9517e-01, -2.8021e+00, -7.3917e-01, -1.5965e-01, -6.9315e-01,\n",
            "          -7.6749e-01,  1.8722e-01, -2.6273e+00,  1.5978e+00]],\n",
            "\n",
            "        [[-5.2410e-01,  1.2209e+00, -7.0954e-01,  6.6153e-01, -1.0208e-02,\n",
            "          -1.3718e+00,  8.7214e-02,  9.7515e-02, -9.4000e-01, -1.9089e+00,\n",
            "          -2.6349e-01, -3.0251e-01, -1.2771e-01,  8.1590e-01,  4.5252e-02,\n",
            "          -9.7049e-01,  2.1943e-01,  4.0164e-02,  5.1099e-01, -6.5225e-01,\n",
            "          -1.9510e+00,  8.8854e-01,  1.0384e-01,  1.3017e+00, -1.2214e+00,\n",
            "          -1.0469e+00, -2.5278e-01, -6.3036e-01,  7.7117e-01,  4.2721e-01,\n",
            "           1.4776e+00,  3.6197e-01, -5.9071e-02,  2.8282e-01, -6.1187e-01,\n",
            "          -1.3898e+00,  3.0126e-01,  4.7866e-01,  5.7152e-01, -4.6194e-01,\n",
            "          -1.7621e+00,  1.7175e+00, -1.0155e+00,  3.0370e-01,  1.5597e+00,\n",
            "           2.5795e-01,  1.8704e-01,  1.1012e+00, -1.4399e+00,  1.0709e+00,\n",
            "          -1.6303e-01, -2.1465e-01, -1.0018e+00,  1.3200e+00,  8.4295e-02,\n",
            "           1.9889e+00,  4.9551e-01,  2.1003e+00, -1.1122e+00,  2.3575e+00,\n",
            "          -1.2636e+00,  1.3579e+00,  2.1417e+00, -2.2553e-01],\n",
            "         [ 2.1662e-01,  4.0669e-01, -3.2600e-01, -6.4019e-01,  5.7927e-01,\n",
            "           1.1891e-01, -9.3017e-01, -2.3492e+00, -2.7050e-01,  2.0185e+00,\n",
            "           2.7611e+00,  4.3577e-01, -2.9341e-01, -1.8907e-01, -2.1020e+00,\n",
            "          -1.4314e+00,  9.5333e-02,  1.2585e+00, -1.7987e+00, -4.4305e-01,\n",
            "           8.7167e-01,  1.1099e+00,  9.0618e-01,  1.6850e+00,  3.8852e-01,\n",
            "          -3.2416e-01, -9.6513e-01,  1.1768e-02, -4.9293e-01,  7.1931e-01,\n",
            "          -3.8682e-01, -2.0366e+00, -1.2794e+00, -2.8585e-01,  7.1915e-02,\n",
            "          -1.8227e-03,  1.3851e-01, -1.2041e+00, -2.0293e-01, -1.9989e+00,\n",
            "           1.1055e+00,  1.4726e+00,  1.4286e+00, -4.7389e-01, -6.2535e-01,\n",
            "           6.1867e-01, -2.7017e+00, -4.8853e-01, -1.1958e-01, -1.9649e+00,\n",
            "           5.7909e-01, -1.3619e-01,  5.7636e-01, -4.0007e-01, -1.1009e+00,\n",
            "           1.0323e+00, -1.1343e+00,  4.2818e-01,  7.3247e-01, -8.0914e-02,\n",
            "           1.5581e+00,  7.0813e-01,  2.9247e-01,  3.0124e-01],\n",
            "         [-1.4900e+00, -1.6533e-01, -1.8447e-01, -1.3912e-01,  1.6157e-01,\n",
            "          -5.3808e-01, -3.0040e-01,  1.3559e-01, -3.8463e-01, -5.0501e-01,\n",
            "          -2.1983e-01, -1.5292e+00, -5.4131e-01, -1.2971e+00, -3.2992e-01,\n",
            "          -1.0868e+00,  3.8079e-01,  1.6092e+00, -7.3209e-01,  3.0799e-01,\n",
            "           1.3062e+00, -7.3070e-01,  3.9039e-01, -1.4834e-01,  1.3070e+00,\n",
            "           1.0679e+00, -1.1328e-01, -5.6679e-01, -1.0558e+00, -1.4405e+00,\n",
            "          -2.6137e-01, -6.6754e-01, -7.9644e-01,  3.9859e-01,  3.2742e-02,\n",
            "           1.7425e+00, -1.1792e+00,  1.2349e+00, -1.7670e+00,  1.4676e+00,\n",
            "           4.5186e-01,  8.9591e-01, -1.5897e+00,  3.1425e-01,  2.9608e+00,\n",
            "          -1.1609e+00,  3.1861e-01, -4.3283e-02, -2.5318e+00,  1.8712e-02,\n",
            "           1.0885e+00,  4.0330e-01, -1.2796e+00,  4.5916e-01, -4.1299e-01,\n",
            "          -6.6169e-01, -1.0385e-01,  7.3817e-01,  2.1460e-01,  1.2012e-02,\n",
            "           4.9681e-02, -4.5595e-02, -2.5239e-01, -8.6195e-01]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2706],\n",
              "        [ 0.0404],\n",
              "        [-0.1763],\n",
              "        [ 0.3445],\n",
              "        [ 0.3219]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size,\n",
        "                                      embed_dim,\n",
        "                                      padding_idx=0)\n",
        "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size,\n",
        "                           batch_first=True)\n",
        "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, text, lengths):\n",
        "        out = self.embedding(text)\n",
        "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False,\n",
        "            batch_first=True\n",
        "        )\n",
        "        out, (hidden, cell) = self.rnn(out)\n",
        "        out = hidden[-1, :, :]\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out= self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embed_dim = 20\n",
        "rnn_hidden_size = 64\n",
        "fc_hidden_size = 64\n",
        "\n",
        "torch.manual_seed(1)\n",
        "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "0n_bPg0lDzI6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_loss = 0, 0\n",
        "    for text_batch, label_batch, lengths in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(text_batch, lengths)[:, 0]\n",
        "        loss = loss_fn(pred, label_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
        "        total_loss += loss.item()*label_batch.size(0)\n",
        "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_loss = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for text_batch, label_batch, lengths in dataloader:\n",
        "            pred = model(text_batch, lengths)[:, 0]\n",
        "            loss = loss_fn(pred, label_batch)\n",
        "            total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
        "            total_loss += loss.item()*label_batch.size(0)\n",
        "    return total_acc/len(list(dataloader.dataset)), total_loss/len(list(dataloader.dataset))\n",
        "\n"
      ],
      "metadata": {
        "id": "e7UUObAnGdwV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    acc_train, loss_train = train(train_dl)\n",
        "    acc_valid, loss_valid = evaluate(valid_dl)\n",
        "    print(f'에포크 {epoch} 정확도: {acc_train:.4f} 검증 정확도: {acc_valid:.4f}')"
      ],
      "metadata": {
        "id": "4EV6Wgq8IA4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y9M-g3V3IaG1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}