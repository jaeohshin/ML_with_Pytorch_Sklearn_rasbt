{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNQFQ+bwamlp7U+fu3/0i/M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaeohshin/ML_with_Pytorch_Sklearn_rasbt/blob/main/ch17_gans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mM8Gq99EI1wE"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '..')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)\n",
        "print(\"GPU Available:\", torch.cuda.is_available())\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    device = \"cpu\""
      ],
      "metadata": {
        "id": "Wr3OtFCh6YBs",
        "outputId": "c7cc367b-a384-4d79-bbfe-0018a8beb7da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.1+cu121\n",
            "GPU Available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "jjY2nuvW6pi5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## define a function for the generator:\n",
        "\n",
        "def make_generator_network(\n",
        "        input_size = 20,\n",
        "        num_hidden_layers=1,\n",
        "        num_hidden_units=100,\n",
        "        num_output_units=748):\n",
        "    model = nn.Sequential()\n",
        "    for i in range(num_hidden_layers):\n",
        "        model.add_module(f'fc_g{i}',\n",
        "                        nn.Linear(input_size,\n",
        "                                  num_hidden_units))\n",
        "        model.add_module(f'relu_g{i}',\n",
        "                         nn.LeakyReLU())\n",
        "        input_size = num_hidden_units\n",
        "\n",
        "    model.add_module(f'fc_g{num_hidden_layers}',\n",
        "                     nn.Linear(input_size, num_output_units))\n",
        "    model.add_module('tanh_g', nn.Tanh())\n",
        "    return model\n",
        "\n",
        "## define a function for the discriminator:\n",
        "\n",
        "def make_discriminator_network(\n",
        "        input_size = 748,\n",
        "        num_hidden_layers = 1,\n",
        "        num_hidden_units=100,\n",
        "        num_output_units=1):\n",
        "    model = nn.Sequential()\n",
        "    for i in range(num_hidden_layers):\n",
        "        model.add_module(f'fc_d{i}',\n",
        "                nn.Linear(input_size,\n",
        "                          num_hidden_units, bias=False))\n",
        "        model.add_module(f'relu_d{i}',\n",
        "                         nn.LeakyReLU())\n",
        "        model.add_module('dropout', nn.Dropout(p=0.5))\n",
        "        input_size = num_hidden_units\n",
        "    model.add_module(f'fc_d{num_hidden_layers}',\n",
        "                     nn.Linear(input_size, num_output_units))\n",
        "    model.add_module('sigmoid', nn.Sigmoid())\n",
        "    return model"
      ],
      "metadata": {
        "id": "S2FDh-_R7a2D"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "image_size = (28, 28)\n",
        "z_size = 20\n",
        "\n",
        "gen_hidden_layers = 1\n",
        "gen_hidden_size = 100\n",
        "disc_hidden_layers = 1\n",
        "disc_hidden_size = 100\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "gen_model = make_generator_network(\n",
        "    input_size=z_size,\n",
        "    num_hidden_layers=gen_hidden_layers,\n",
        "    num_hidden_units=gen_hidden_size,\n",
        "    num_output_units=np.prod(image_size))\n",
        "\n",
        "print(gen_model)"
      ],
      "metadata": {
        "id": "3wsl_MG3_w-f",
        "outputId": "08a57ea8-bcb0-4370-b9ec-5970b573f90b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (fc_g0): Linear(in_features=20, out_features=100, bias=True)\n",
            "  (relu_g0): LeakyReLU(negative_slope=0.01)\n",
            "  (fc_g1): Linear(in_features=100, out_features=784, bias=True)\n",
            "  (tanh_g): Tanh()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disc_model = make_discriminator_network(\n",
        "    input_size=np.prod(image_size),\n",
        "    num_hidden_layers=disc_hidden_layers,\n",
        "    num_hidden_units=disc_hidden_size)\n",
        "\n",
        "print(disc_model)"
      ],
      "metadata": {
        "id": "JFUrKNUAcJ3k",
        "outputId": "07014ba4-7bda-4724-fc37-e2339890fd30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (fc_d0): Linear(in_features=784, out_features=100, bias=False)\n",
            "  (relu_d0): LeakyReLU(negative_slope=0.01)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc_d1): Linear(in_features=100, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "image_path = './'\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5), std=(0.5)),\n",
        "])\n",
        "mnist_dataset = torchvision.datasets.MNIST(root=image_path,\n",
        "                                           train=True,\n",
        "                                           transform=transform,\n",
        "                                           download=True)\n",
        "\n",
        "example, label = next(iter(mnist_dataset))\n",
        "print(f'Min: {example.min()} Max: {example.max()}')\n",
        "print(example.shape)"
      ],
      "metadata": {
        "id": "BQFzKi6qcLoV",
        "outputId": "efc2a5a5-e590-46a9-d51b-a70dffb154fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min: -1.0 Max: 1.0\n",
            "torch.Size([1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_noise(batch_size, z_size, mode_z):\n",
        "    if mode_z == 'uniform':\n",
        "        input_z = torch.rand(batch_size, z_size)*2 - 1\n",
        "    elif mode_z == 'normal':\n",
        "        input_z = torch.randn(batch_size, z_size)\n",
        "    return input_z"
      ],
      "metadata": {
        "id": "ZoeDBiGVcSsw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "dataloader = DataLoader(mnist_dataset, batch_size, shuffle=False)\n",
        "input_real, label = next(iter(dataloader))\n",
        "input_real = input_real.view(batch_size, -1)\n",
        "\n",
        "torch.manual_seed(1)\n",
        "mode_z = 'uniform'  # 'uniform' vs. 'normal'\n",
        "input_z = create_noise(batch_size, z_size, mode_z)\n",
        "\n",
        "print('input-z -- shape:', input_z.shape)\n",
        "print('input-real -- shape:', input_real.shape)\n",
        "\n",
        "g_output = gen_model(input_z)\n",
        "print('Output of G -- shape:', g_output.shape)\n",
        "\n",
        "d_proba_real = disc_model(input_real)\n",
        "d_proba_fake = disc_model(g_output)\n",
        "print('Disc. (real) -- shape:', d_proba_real.shape)\n",
        "print('Disc. (fake) -- shape:', d_proba_fake.shape)"
      ],
      "metadata": {
        "id": "fIoIIWXlcVUD",
        "outputId": "a7984c75-e9c2-466a-d487-35a2eb429d75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input-z -- shape: torch.Size([32, 20])\n",
            "input-real -- shape: torch.Size([32, 784])\n",
            "Output of G -- shape: torch.Size([32, 784])\n",
            "Disc. (real) -- shape: torch.Size([32, 1])\n",
            "Disc. (fake) -- shape: torch.Size([32, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "## Loss for the Generator\n",
        "g_labels_real = torch.ones_like(d_proba_fake)\n",
        "g_loss = loss_fn(d_proba_fake, g_labels_real)\n",
        "print(f'Generator Loss: {g_loss:.4f}')\n",
        "\n",
        "## Loss for the Discriminator\n",
        "d_labels_real = torch.ones_like(d_proba_real)\n",
        "d_labels_fake = torch.zeros_like(d_proba_fake)\n",
        "\n",
        "d_loss_real = loss_fn(d_proba_real, d_labels_real)\n",
        "d_loss_fake = loss_fn(d_proba_fake, d_labels_fake)\n",
        "print(f'Discriminator Losses: Real {d_loss_real:.4f} Fake {d_loss_fake:.4f}')"
      ],
      "metadata": {
        "id": "FpTL7ZnKcYcs",
        "outputId": "f1ad1937-b112-4ced-f5be-dd13ee3d784b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator Loss: 0.6983\n",
            "Discriminator Losses: Real 0.7479 Fake 0.6885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "\n",
        "## Set up the dataset\n",
        "mnist_dl = DataLoader(mnist_dataset, batch_size=batch_size,\n",
        "                      shuffle=True, drop_last=True)\n",
        "\n",
        "## Set up the models\n",
        "gen_model = make_generator_network(\n",
        "    input_size=z_size,\n",
        "    num_hidden_layers=gen_hidden_layers,\n",
        "    num_hidden_units=gen_hidden_size,\n",
        "    num_output_units=np.prod(image_size)).to(device)\n",
        "\n",
        "disc_model = make_discriminator_network(\n",
        "    input_size=np.prod(image_size),\n",
        "    num_hidden_layers=disc_hidden_layers,\n",
        "    num_hidden_units=disc_hidden_size).to(device)\n",
        "\n",
        "## Loss function and optimizers:\n",
        "loss_fn = nn.BCELoss()\n",
        "g_optimizer = torch.optim.Adam(gen_model.parameters())\n",
        "d_optimizer = torch.optim.Adam(disc_model.parameters())"
      ],
      "metadata": {
        "id": "peuP7ptjcqsh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Train the discriminator\n",
        "def d_train(x):\n",
        "    disc_model.zero_grad()\n",
        "\n",
        "    # Train discriminator with a real batch\n",
        "    batch_size = x.size(0)\n",
        "    x = x.view(batch_size, -1).to(device)\n",
        "    d_labels_real = torch.ones(batch_size, 1, device=device)\n",
        "\n",
        "    d_proba_real = disc_model(x)\n",
        "    d_loss_real = loss_fn(d_proba_real, d_labels_real)\n",
        "\n",
        "    # Train discriminator on a fake batch\n",
        "    input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
        "    g_output = gen_model(input_z)\n",
        "\n",
        "    d_proba_fake = disc_model(g_output)\n",
        "    d_labels_fake = torch.zeros(batch_size, 1, device=device)\n",
        "    d_loss_fake = loss_fn(d_proba_fake, d_labels_fake)\n",
        "\n",
        "    # gradient backprop & optimize ONLY D's parameters\n",
        "    d_loss = d_loss_real + d_loss_fake\n",
        "    d_loss.backward()\n",
        "    d_optimizer.step()\n",
        "\n",
        "    return d_loss.data.item(), d_proba_real.detach(), d_proba_fake.detach()"
      ],
      "metadata": {
        "id": "JI3HlWCjctG1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Train the generator\n",
        "def g_train(x):\n",
        "    gen_model.zero_grad()\n",
        "\n",
        "    batch_size = x.size(0)\n",
        "    input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
        "    g_labels_real = torch.ones(batch_size, 1, device=device)\n",
        "\n",
        "    g_output = gen_model(input_z)\n",
        "    d_proba_fake = disc_model(g_output)\n",
        "    g_loss = loss_fn(d_proba_fake, g_labels_real)\n",
        "\n",
        "    # gradient backprop & optimize ONLY G's parameters\n",
        "    g_loss.backward()\n",
        "    g_optimizer.step()\n",
        "\n",
        "    return g_loss.data.item()"
      ],
      "metadata": {
        "id": "Ocjx-QzicvMl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
        "\n",
        "def create_samples(g_model, input_z):\n",
        "    g_output = g_model(input_z)\n",
        "    images = torch.reshape(g_output, (batch_size, *image_size))\n",
        "    return (images+1)/2.0\n",
        "\n",
        "epoch_samples = []\n",
        "\n",
        "all_d_losses = []\n",
        "all_g_losses = []\n",
        "\n",
        "all_d_real = []\n",
        "all_d_fake = []\n",
        "\n",
        "num_epochs = 100\n",
        "torch.manual_seed(1)\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    d_losses, g_losses = [], []\n",
        "    d_vals_real, d_vals_fake = [], []\n",
        "    for i, (x, _) in enumerate(mnist_dl):\n",
        "        d_loss, d_proba_real, d_proba_fake = d_train(x)\n",
        "        d_losses.append(d_loss)\n",
        "        g_losses.append(g_train(x))\n",
        "\n",
        "        d_vals_real.append(d_proba_real.mean().cpu())\n",
        "        d_vals_fake.append(d_proba_fake.mean().cpu())\n",
        "\n",
        "    all_d_losses.append(torch.tensor(d_losses).mean())\n",
        "    all_g_losses.append(torch.tensor(g_losses).mean())\n",
        "    all_d_real.append(torch.tensor(d_vals_real).mean())\n",
        "    all_d_fake.append(torch.tensor(d_vals_fake).mean())\n",
        "    print(f'Epoch {epoch:03d} | Avg Losses >>'\n",
        "          f' G/D {all_g_losses[-1]:.4f}/{all_d_losses[-1]:.4f}'\n",
        "          f' [D-Real: {all_d_real[-1]:.4f} D-Fake: {all_d_fake[-1]:.4f}]')\n",
        "    epoch_samples.append(\n",
        "        create_samples(gen_model, fixed_z).detach().cpu().numpy())"
      ],
      "metadata": {
        "id": "8b6o4GQNcyp8",
        "outputId": "a925364e-bac9-440c-92c2-9eaa1c76b038",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001 | Avg Losses >> G/D 0.8944/0.9068 [D-Real: 0.8035 D-Fake: 0.4717]\n",
            "Epoch 002 | Avg Losses >> G/D 0.9469/1.1271 [D-Real: 0.6164 D-Fake: 0.4318]\n",
            "Epoch 003 | Avg Losses >> G/D 0.9596/1.1998 [D-Real: 0.5790 D-Fake: 0.4277]\n",
            "Epoch 004 | Avg Losses >> G/D 0.9415/1.2163 [D-Real: 0.5737 D-Fake: 0.4305]\n",
            "Epoch 005 | Avg Losses >> G/D 0.9270/1.2284 [D-Real: 0.5705 D-Fake: 0.4286]\n",
            "Epoch 006 | Avg Losses >> G/D 0.9453/1.2473 [D-Real: 0.5620 D-Fake: 0.4335]\n",
            "Epoch 007 | Avg Losses >> G/D 1.0020/1.1734 [D-Real: 0.5897 D-Fake: 0.4058]\n",
            "Epoch 008 | Avg Losses >> G/D 1.0015/1.1883 [D-Real: 0.5890 D-Fake: 0.4110]\n",
            "Epoch 009 | Avg Losses >> G/D 0.9548/1.2096 [D-Real: 0.5805 D-Fake: 0.4229]\n",
            "Epoch 010 | Avg Losses >> G/D 0.9074/1.2498 [D-Real: 0.5619 D-Fake: 0.4359]\n",
            "Epoch 011 | Avg Losses >> G/D 0.9841/1.2001 [D-Real: 0.5831 D-Fake: 0.4135]\n",
            "Epoch 012 | Avg Losses >> G/D 0.9437/1.2165 [D-Real: 0.5803 D-Fake: 0.4267]\n",
            "Epoch 013 | Avg Losses >> G/D 0.9947/1.1981 [D-Real: 0.5860 D-Fake: 0.4148]\n",
            "Epoch 014 | Avg Losses >> G/D 0.9812/1.2052 [D-Real: 0.5852 D-Fake: 0.4206]\n",
            "Epoch 015 | Avg Losses >> G/D 0.9600/1.2153 [D-Real: 0.5790 D-Fake: 0.4233]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-cd933ef4649d>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0md_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0md_vals_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_vals_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_proba_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_proba_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0md_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I;16\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyteorder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"little\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"I;16B\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}